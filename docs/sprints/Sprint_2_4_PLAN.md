# Sprint 2.4: Optimizaci贸n de Hiperpar谩metros

## Objetivo
Optimizar sistem谩ticamente los hiperpar谩metros del modelo LightGBM ganador mediante Optuna (Bayesian optimization) para maximizar el rendimiento en detecci贸n de fraude manteniendo eficiencia computacional.

## Contexto
- **Sprint anterior**: Sprint 2.3 identific贸 LightGBM como modelo 贸ptimo (F1: 0.5404, PR-AUC: 0.6022)
- **Configuraci贸n actual**: Hiperpar谩metros por defecto con ajustes b谩sicos
- **Oportunidad**: Optimizaci贸n sistem谩tica puede mejorar significativamente el rendimiento

## Tareas del Sprint

### 2.4.1 Framework de Optimizaci贸n con Optuna
- [ ] **Optuna integration**: Framework de optimizaci贸n bayesiana
- [ ] **Objective function**: Funci贸n objetivo basada en PR-AUC con penalizaci贸n por tiempo
- [ ] **Search space**: Definici贸n de espacios de b煤squeda para cada hiperpar谩metro
- [ ] **Pruning**: Early stopping para optimizaci贸n eficiente
- [ ] **Multi-objective**: Balance entre performance y eficiencia computacional

### 2.4.2 Hiperpar谩metros Target para LightGBM
- [ ] **n_estimators**: N煤mero de 谩rboles (50-500)
- [ ] **learning_rate**: Tasa de aprendizaje (0.01-0.3)
- [ ] **num_leaves**: Complejidad del 谩rbol (10-100)
- [ ] **max_depth**: Profundidad m谩xima (-1, 3-15)
- [ ] **feature_fraction**: Submuestreo de features (0.4-1.0)
- [ ] **bagging_fraction**: Submuestreo de datos (0.4-1.0)
- [ ] **min_data_in_leaf**: M铆nimo de datos por hoja (5-100)
- [ ] **lambda_l1**: Regularizaci贸n L1 (0-10)
- [ ] **lambda_l2**: Regularizaci贸n L2 (0-10)

### 2.4.3 Estrategias de Optimizaci贸n
- [ ] **Bayesian optimization**: Optuna TPE sampler para exploraci贸n eficiente
- [ ] **Cross-validation**: Validaci贸n cruzada durante optimizaci贸n
- [ ] **Budget control**: L铆mite de trials y tiempo m谩ximo
- [ ] **Hyperband pruning**: Terminaci贸n temprana de trials pobres
- [ ] **Study persistence**: SQLite database para continuidad

### 2.4.4 Evaluaci贸n y Comparaci贸n
- [ ] **Baseline comparison**: Comparaci贸n con LightGBM actual
- [ ] **Performance metrics**: PR-AUC, F1-Score, Precision, Recall
- [ ] **Efficiency analysis**: Tiempo de entrenamiento e inferencia
- [ ] **Overfitting detection**: An谩lisis de learning curves
- [ ] **Robustness testing**: Validaci贸n en diferentes folds

## Criterios de xito
1. **Performance**: Mejora significativa sobre LightGBM baseline (>5% PR-AUC)
2. **Eficiencia**: Tiempo de entrenamiento razonable (<200s)
3. **Robustez**: Rendimiento consistente en cross-validation
4. **Reproducibilidad**: Hiperpar谩metros 贸ptimos documentados y versionados
5. **Producci贸n**: Modelo optimizado ready para staging deployment

## Tecnolog铆as a Integrar
- **Optuna 4.5.0**: Hyperparameter optimization framework
- **SQLite**: Study persistence para continuidad
- **MLflow**: Tracking de optimization trials
- **LightGBM**: Target model para optimizaci贸n
- **Cross-validation**: StratifiedKFold para robustez

## Framework de Optimizaci贸n

### Funci贸n Objetivo Multi-criterio
```python
def objective(trial):
    # Suggest hyperparameters
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 500),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
        'num_leaves': trial.suggest_int('num_leaves', 10, 100),
        'max_depth': trial.suggest_int('max_depth', -1, 15),
        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),
        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),
        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100),
        'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),
        'lambda_l2': trial.suggest_float('lambda_l2', 0, 10)
    }
    
    # Train model with CV
    pr_auc_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='average_precision')
    
    # Multi-objective: maximize PR-AUC, minimize training time
    pr_auc = np.mean(pr_auc_scores)
    time_penalty = training_time / 300  # Normalize by 5 minutes
    
    return pr_auc - 0.1 * time_penalty  # Weighted objective
```

### Search Strategy
- **TPE Sampler**: Tree-structured Parzen Estimator para exploration/exploitation balance
- **Median Pruner**: Early stopping de trials poco prometedores
- **100 trials**: Budget inicial para optimizaci贸n
- **Parallel execution**: Utilizaci贸n de m煤ltiples cores

## Entregables Esperados
1. `src/optimization/hyperparameter_optimizer.py`: Framework de optimizaci贸n
2. `scripts/lightgbm_optimization.py`: Runner de optimizaci贸n LightGBM
3. `docs/sprints/Sprint_2_4_Optimization_Results.md`: An谩lisis detallado
4. **Optuna Study**: Base de datos SQLite con historial completo
5. **Optimized Model**: LightGBM con hiperpar谩metros 贸ptimos
6. **MLflow Experiments**: Tracking de todos los trials

## Cronograma Estimado
- **Setup**: 30 minutos (framework de optimizaci贸n)
- **Optimization**: 2-3 horas (100 trials con CV)
- **Analysis**: 1 hora (evaluaci贸n y comparaci贸n)
- **Documentation**: 30 minutos (resultados y conclusiones)

## M茅tricas de Seguimiento
- **Objective value**: PR-AUC penalizada por tiempo
- **Best trial performance**: Mejor PR-AUC alcanzada
- **Convergence**: Trials hasta estabilizaci贸n
- **Hyperparameter importance**: An谩lisis de sensibilidad
- **Final improvement**: Mejora vs baseline

## Estrategia Post-Optimizaci贸n
1. **A/B Testing**: Comparaci贸n rigurosa optimizado vs baseline
2. **Ensemble consideration**: Combinaci贸n con otros modelos top
3. **Production deployment**: Modelo optimizado a staging
4. **Monitoring setup**: Drift detection de hiperpar谩metros
5. **Retraining protocol**: Periodicidad de re-optimizaci贸n

---

**Estado**:  **INICIANDO SPRINT 2.4**  
**Fecha inicio**: 2024-12-31  
**Target**: Maximizar PR-AUC de LightGBM mediante optimizaci贸n bayesiana  
**Sprint owner**: AEGIS Fraud Detection Team
