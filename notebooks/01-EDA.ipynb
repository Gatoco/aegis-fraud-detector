{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87cd59cb",
   "metadata": {},
   "source": [
    "# Aegis Fraud Detector - Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Sprint 1.1**: An√°lisis Exploratorio de Datos Riguroso  \n",
    "**Dataset**: IEEE-CIS Fraud Detection  \n",
    "**Fecha**: Agosto 2025  \n",
    "**Metodolog√≠a**: EDA basado en scripts versionados para garantizar reproducibilidad\n",
    "\n",
    "## Objetivos del An√°lisis\n",
    "\n",
    "1. **Comprensi√≥n profunda del dataset**: Estructura, tipos de datos, y calidad general\n",
    "2. **An√°lisis de la variable objetivo**: Prevalencia de fraude y patrones temporales\n",
    "3. **Exploraci√≥n de features**: Distribuciones, correlaciones, y valores faltantes\n",
    "4. **Identificaci√≥n de insights**: Patrones, anomal√≠as, y oportunidades de feature engineering\n",
    "5. **Documentaci√≥n de hallazgos**: Base para decisiones de modelado futuras\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45421445",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n e Importaci√≥n de Librer√≠as\n",
    "\n",
    "**Nota importante**: Este notebook utiliza exclusivamente funciones del m√≥dulo `src/data/exploration.py` para garantizar la reproducibilidad y el versionado del c√≥digo de an√°lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16271284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuraci√≥n completada\n",
      "üìÇ Directorio de trabajo: c:\\Users\\Gat\\Documents\\GitHub\\aegis-fraud-detector\\notebooks\n",
      "üìä Versi√≥n de pandas: 2.3.1\n",
      "üîç Versi√≥n de numpy: 2.2.6\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n del entorno\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Agregar el directorio src al path para importar nuestros m√≥dulos\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "sys.path.append(str(project_root / 'src'))\n",
    "\n",
    "# Importaciones est√°ndar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Importar nuestro m√≥dulo de exploraci√≥n personalizado\n",
    "from data.exploration import FraudDataExplorer, create_eda_plotting_functions\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_style(\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar pandas para mostrar m√°s columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n completada\")\n",
    "print(f\"üìÇ Directorio de trabajo: {os.getcwd()}\")\n",
    "print(f\"üìä Versi√≥n de pandas: {pd.__version__}\")\n",
    "print(f\"üîç Versi√≥n de numpy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b4858",
   "metadata": {},
   "source": [
    "## 2. Inicializaci√≥n del Explorador de Datos\n",
    "\n",
    "Utilizamos la clase `FraudDataExplorer` para realizar todos los an√°lisis de manera estructurada y reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6d42b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Explorador inicializado\n",
      "üìÅ Ruta de datos: c:\\Users\\Gat\\Documents\\GitHub\\aegis-fraud-detector\\data\\01_raw\n",
      "üìã Verificando archivos disponibles...\n",
      "  ‚úÖ train_transaction.csv (651.7 MB)\n",
      "  ‚úÖ train_identity.csv (25.3 MB)\n",
      "  ‚úÖ test_transaction.csv (584.8 MB)\n",
      "  ‚úÖ test_identity.csv (24.6 MB)\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el explorador de datos\n",
    "data_path = project_root / \"data\" / \"01_raw\"\n",
    "explorer = FraudDataExplorer(data_path=str(data_path))\n",
    "\n",
    "print(f\"üîç Explorador inicializado\")\n",
    "print(f\"üìÅ Ruta de datos: {data_path}\")\n",
    "print(f\"üìã Verificando archivos disponibles...\")\n",
    "\n",
    "# Verificar que los archivos existan\n",
    "required_files = [\n",
    "    \"train_transaction.csv\",\n",
    "    \"train_identity.csv\",\n",
    "    \"test_transaction.csv\",\n",
    "    \"test_identity.csv\"\n",
    "]\n",
    "\n",
    "for file in required_files:\n",
    "    file_path = data_path / file\n",
    "    if file_path.exists():\n",
    "        file_size = file_path.stat().st_size / (1024**2)  # MB\n",
    "        print(f\"  ‚úÖ {file} ({file_size:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {file} - No encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a8a26",
   "metadata": {},
   "source": [
    "## 3. Carga y Revisi√≥n General de Datasets\n",
    "\n",
    "Cargamos todos los datasets del IEEE-CIS Fraud Detection y realizamos una primera inspecci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fa8d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar todos los datasets\n",
    "print(\"üîÑ Cargando datasets...\")\n",
    "datasets = explorer.load_datasets()\n",
    "\n",
    "print(\"\\nüìä RESUMEN DE DATASETS CARGADOS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    memory_usage = df.memory_usage(deep=True).sum() / (1024**2)\n",
    "    print(f\"\\n{name.upper()}:\")\n",
    "    print(f\"  üìè Dimensiones: {df.shape}\")\n",
    "    print(f\"  üíæ Memoria: {memory_usage:.1f} MB\")\n",
    "    print(f\"  üî¢ Tipos de datos: {dict(df.dtypes.value_counts())}\")\n",
    "    \n",
    "    if name == 'merged_train':\n",
    "        print(f\"  üéØ Variable objetivo (isFraud): {df['isFraud'].value_counts().to_dict()}\")\n",
    "\n",
    "print(\"\\n‚úÖ Carga completada exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ab29f",
   "metadata": {},
   "source": [
    "## 4. An√°lisis Comprehensive del Dataset\n",
    "\n",
    "Realizamos un an√°lisis detallado de la estructura y composici√≥n del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8840df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar an√°lisis de overview completo\n",
    "print(\"üîç Realizando an√°lisis comprehensive del dataset...\")\n",
    "overview_results = explorer.analyze_dataset_overview()\n",
    "\n",
    "print(\"\\nüìã AN√ÅLISIS DE ESTRUCTURA DEL DATASET:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Mostrar dimensiones\n",
    "print(\"\\nüìè DIMENSIONES:\")\n",
    "for dataset_name, shape in overview_results['shape'].items():\n",
    "    print(f\"  {dataset_name}: {shape[0]:,} filas √ó {shape[1]} columnas\")\n",
    "\n",
    "# Mostrar uso de memoria\n",
    "print(\"\\nüíæ USO DE MEMORIA:\")\n",
    "for dataset_name, memory in overview_results['memory_usage'].items():\n",
    "    print(f\"  {dataset_name}: {memory:.1f} MB\")\n",
    "\n",
    "# Mostrar categor√≠as de features\n",
    "print(\"\\nüè∑Ô∏è CATEGOR√çAS DE FEATURES:\")\n",
    "for category, count in overview_results['feature_counts'].items():\n",
    "    print(f\"  {category}: {count} features\")\n",
    "\n",
    "# Detalles de las categor√≠as m√°s importantes\n",
    "print(\"\\nüîç FEATURES POR CATEGOR√çA:\")\n",
    "important_categories = ['card_features', 'categorical_features', 'continuous_features']\n",
    "for category in important_categories:\n",
    "    features = overview_results['feature_categories'].get(category, [])\n",
    "    print(f\"\\n  {category.upper()}:\")\n",
    "    print(f\"    Cantidad: {len(features)}\")\n",
    "    if features:\n",
    "        print(f\"    Ejemplos: {features[:5]}\")\n",
    "        if len(features) > 5:\n",
    "            print(f\"    ... y {len(features) - 5} m√°s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07ca64",
   "metadata": {},
   "source": [
    "## 5. An√°lisis de Valores Faltantes\n",
    "\n",
    "Investigaci√≥n profunda de los patrones de valores faltantes en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a107eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis comprehensive de valores faltantes\n",
    "print(\"üîç Analizando patrones de valores faltantes...\")\n",
    "missing_results = explorer.analyze_missing_values()\n",
    "\n",
    "print(\"\\nüï≥Ô∏è AN√ÅLISIS DE VALORES FALTANTES:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for dataset_name, missing_info in missing_results.items():\n",
    "    print(f\"\\nüìä {dataset_name.upper()}:\")\n",
    "    print(f\"  Total features: {missing_info['total_features']}\")\n",
    "    print(f\"  Features completas: {missing_info['complete_features']}\")\n",
    "    print(f\"  Features con valores faltantes: {missing_info['features_with_missing']}\")\n",
    "    print(f\"  Features con >90% faltantes: {missing_info['heavily_missing_features']}\")\n",
    "    print(f\"  Features con 50-90% faltantes: {missing_info['moderately_missing_features']}\")\n",
    "    print(f\"  Features con <50% faltantes: {missing_info['lightly_missing_features']}\")\n",
    "    \n",
    "    # Mostrar top 10 features con m√°s valores faltantes\n",
    "    top_missing = missing_info['missing_summary'].head(10)\n",
    "    if len(top_missing) > 0:\n",
    "        print(f\"\\n  üîù TOP 10 FEATURES CON M√ÅS VALORES FALTANTES:\")\n",
    "        for _, row in top_missing.iterrows():\n",
    "            print(f\"    {row['column']}: {row['missing_percentage']:.1f}% ({row['missing_count']:,} valores)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679e6e1b",
   "metadata": {},
   "source": [
    "## 6. An√°lisis Profundo de la Variable Objetivo (isFraud)\n",
    "\n",
    "**Investigaci√≥n exhaustiva del fraude**: Prevalencia, patrones temporales, y caracter√≠sticas distintivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c287cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis profundo de la variable objetivo\n",
    "print(\"üéØ Analizando variable objetivo (isFraud) en profundidad...\")\n",
    "target_results = explorer.analyze_target_variable()\n",
    "\n",
    "print(\"\\nüéØ AN√ÅLISIS DE LA VARIABLE OBJETIVO:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Distribuci√≥n b√°sica\n",
    "basic_dist = target_results['basic_distribution']\n",
    "print(f\"\\nüìä DISTRIBUCI√ìN B√ÅSICA:\")\n",
    "print(f\"  Total transacciones: {basic_dist['total_transactions']:,}\")\n",
    "print(f\"  Transacciones fraudulentas: {basic_dist['fraud_transactions']:,}\")\n",
    "print(f\"  Transacciones leg√≠timas: {basic_dist['legitimate_transactions']:,}\")\n",
    "print(f\"  Tasa de fraude: {basic_dist['fraud_rate']:.3f}%\")\n",
    "print(f\"  Ratio de desbalance: 1:{basic_dist['class_imbalance_ratio']:.0f}\")\n",
    "\n",
    "# An√°lisis de cantidad de transacciones\n",
    "if 'amount_patterns' in target_results:\n",
    "    amount_patterns = target_results['amount_patterns']\n",
    "    print(f\"\\nüí∞ PATRONES EN MONTOS DE TRANSACCI√ìN:\")\n",
    "    print(f\"  Monto mediano - Fraude: ${amount_patterns['median_fraud_amount']:.2f}\")\n",
    "    print(f\"  Monto mediano - Leg√≠timo: ${amount_patterns['median_legit_amount']:.2f}\")\n",
    "    print(f\"  Correlaci√≥n monto-fraude: {amount_patterns['amount_correlation_with_fraud']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n  üìà ESTAD√çSTICAS DE MONTOS FRAUDULENTOS:\")\n",
    "    fraud_stats = amount_patterns['fraud_amount_stats']\n",
    "    print(f\"    Media: ${fraud_stats['mean']:.2f}\")\n",
    "    print(f\"    Mediana: ${fraud_stats['50%']:.2f}\")\n",
    "    print(f\"    Desv. est√°ndar: ${fraud_stats['std']:.2f}\")\n",
    "    print(f\"    Rango: ${fraud_stats['min']:.2f} - ${fraud_stats['max']:.2f}\")\n",
    "\n",
    "# An√°lisis temporal\n",
    "if 'temporal_patterns' in target_results:\n",
    "    temporal = target_results['temporal_patterns']\n",
    "    print(f\"\\n‚è∞ PATRONES TEMPORALES:\")\n",
    "    print(f\"  Hora pico de fraude: {temporal['peak_fraud_hour']:.0f}:00\")\n",
    "    print(f\"  D√≠a pico de fraude: {int(temporal['peak_fraud_day'])} (0=Lunes, 6=Domingo)\")\n",
    "    print(f\"  Varianza de fraude por hora: {temporal['fraud_rate_variance_hourly']:.6f}\")\n",
    "    print(f\"  Varianza de fraude por d√≠a: {temporal['fraud_rate_variance_daily']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f23c70",
   "metadata": {},
   "source": [
    "## 7. Visualizaci√≥n de Patrones de la Variable Objetivo\n",
    "\n",
    "Generamos visualizaciones para entender mejor los patrones de fraude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear funciones de plotting\n",
    "plotting_functions = create_eda_plotting_functions()\n",
    "\n",
    "# Visualizar distribuci√≥n de la variable objetivo\n",
    "print(\"üìà Generando visualizaciones de la variable objetivo...\")\n",
    "\n",
    "# Gr√°fico de distribuci√≥n del fraude\n",
    "fraud_counts = explorer.merged_train['isFraud'].value_counts()\n",
    "plotting_functions['plot_target_distribution'](fraud_counts)\n",
    "\n",
    "# Patrones temporales si est√°n disponibles\n",
    "if 'temporal_patterns' in target_results:\n",
    "    temporal = target_results['temporal_patterns']\n",
    "    hourly_data = temporal['hourly_patterns']\n",
    "    daily_data = temporal['daily_patterns']\n",
    "    \n",
    "    plotting_functions['plot_temporal_patterns'](hourly_data, daily_data)\n",
    "    \n",
    "    # Mostrar datos temporales en formato tabular\n",
    "    print(\"\\n‚è∞ DATOS TEMPORALES DETALLADOS:\")\n",
    "    print(\"\\nüìä Fraude por hora del d√≠a:\")\n",
    "    print(hourly_data.round(4))\n",
    "    \n",
    "    print(\"\\nüìä Fraude por d√≠a de la semana:\")\n",
    "    daily_data['day_name'] = ['Lun', 'Mar', 'Mi√©', 'Jue', 'Vie', 'S√°b', 'Dom']\n",
    "    print(daily_data[['day_name', 'total_transactions', 'fraud_count', 'fraud_rate']].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44cb0a",
   "metadata": {},
   "source": [
    "## 8. An√°lisis de Distribuciones de Features\n",
    "\n",
    "Exploraci√≥n de las distribuciones de las features m√°s importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de distribuciones de features\n",
    "print(\"üîç Analizando distribuciones de features clave...\")\n",
    "distribution_results = explorer.analyze_feature_distributions(sample_size=10000)\n",
    "\n",
    "print(\"\\nüìä AN√ÅLISIS DE DISTRIBUCIONES:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Mostrar estad√≠sticas de las features num√©ricas m√°s importantes\n",
    "print(\"\\nüî¢ TOP FEATURES NUM√âRICAS:\")\n",
    "numeric_features = {k: v for k, v in distribution_results.items() \n",
    "                   if k != 'categorical_analysis' and isinstance(v, dict)}\n",
    "\n",
    "# Ordenar por importancia (menos valores faltantes y m√°s varianza)\n",
    "feature_importance = []\n",
    "for feature, stats in numeric_features.items():\n",
    "    if 'missing_percentage' in stats and 'std' in stats:\n",
    "        importance_score = (100 - stats['missing_percentage']) * np.log1p(stats['std'])\n",
    "        feature_importance.append((feature, importance_score, stats))\n",
    "\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nMostrando las top 10 features num√©ricas m√°s relevantes:\")\n",
    "for i, (feature, score, stats) in enumerate(feature_importance[:10]):\n",
    "    print(f\"\\n{i+1}. {feature}:\")\n",
    "    print(f\"    Media: {stats.get('mean', 'N/A'):.4f}\")\n",
    "    print(f\"    Mediana: {stats.get('median', 'N/A'):.4f}\")\n",
    "    print(f\"    Desv. est√°ndar: {stats.get('std', 'N/A'):.4f}\")\n",
    "    print(f\"    Skewness: {stats.get('skewness', 'N/A'):.4f}\")\n",
    "    print(f\"    Valores √∫nicos: {stats.get('unique_values', 'N/A')}\")\n",
    "    print(f\"    Valores faltantes: {stats.get('missing_percentage', 'N/A'):.1f}%\")\n",
    "    print(f\"    Outliers: {stats.get('outlier_percentage', 'N/A'):.1f}%\")\n",
    "\n",
    "# An√°lisis de features categ√≥ricas\n",
    "if 'categorical_analysis' in distribution_results:\n",
    "    categorical_stats = distribution_results['categorical_analysis']\n",
    "    print(f\"\\nüè∑Ô∏è FEATURES CATEG√ìRICAS ANALIZADAS: {len(categorical_stats)}\")\n",
    "    \n",
    "    for feature, stats in list(categorical_stats.items())[:5]:\n",
    "        print(f\"\\n  {feature}:\")\n",
    "        print(f\"    Valores √∫nicos: {stats['unique_values']}\")\n",
    "        print(f\"    Valor m√°s frecuente: {stats['most_frequent']}\")\n",
    "        print(f\"    Valores faltantes: {stats['missing_percentage']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06bba37",
   "metadata": {},
   "source": [
    "## 9. An√°lisis de Correlaciones\n",
    "\n",
    "Exploraci√≥n de las correlaciones entre features y con la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ee2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de correlaciones\n",
    "print(\"üîó Analizando correlaciones entre features...\")\n",
    "correlation_results = explorer.analyze_correlations(method='pearson')\n",
    "\n",
    "print(\"\\nüîó AN√ÅLISIS DE CORRELACIONES:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Correlaciones m√°s fuertes con la variable objetivo\n",
    "if 'target_correlations' in correlation_results:\n",
    "    target_corrs = correlation_results['target_correlations']\n",
    "    \n",
    "    print(\"\\nüéØ CORRELACIONES M√ÅS FUERTES CON isFraud:\")\n",
    "    print(\"\\n  üìà Correlaciones positivas m√°s altas:\")\n",
    "    for feature, corr in list(target_corrs['top_positive'].items())[:10]:\n",
    "        print(f\"    {feature}: {corr:.4f}\")\n",
    "    \n",
    "    print(\"\\n  üìâ Correlaciones negativas m√°s fuertes:\")\n",
    "    negative_corrs = target_corrs['top_negative']\n",
    "    for feature, corr in list(negative_corrs.items())[:10]:\n",
    "        if corr < 0:  # Solo mostrar correlaciones negativas\n",
    "            print(f\"    {feature}: {corr:.4f}\")\n",
    "\n",
    "# Multicolinealidad\n",
    "high_corrs = correlation_results.get('high_correlations', [])\n",
    "print(f\"\\n‚ö†Ô∏è MULTICOLINEALIDAD DETECTADA:\")\n",
    "print(f\"  Pares de features con correlaci√≥n > 0.8: {len(high_corrs)}\")\n",
    "\n",
    "if high_corrs:\n",
    "    print(\"\\n  üîç Ejemplos de alta correlaci√≥n:\")\n",
    "    for pair in high_corrs[:10]:  # Mostrar primeros 10\n",
    "        print(f\"    {pair['feature1']} ‚Üî {pair['feature2']}: {pair['correlation']:.4f}\")\n",
    "    \n",
    "    if len(high_corrs) > 10:\n",
    "        print(f\"    ... y {len(high_corrs) - 10} pares m√°s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea976bd",
   "metadata": {},
   "source": [
    "## 10. Visualizaci√≥n de Correlaciones y Distribuciones\n",
    "\n",
    "Heatmaps y distribuciones clave para insights visuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0592652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar correlaciones\n",
    "print(\"üìà Generando visualizaciones de correlaciones...\")\n",
    "\n",
    "# Heatmap de correlaciones\n",
    "correlation_matrix = correlation_results['correlation_matrix']\n",
    "plotting_functions['plot_correlation_heatmap'](correlation_matrix)\n",
    "\n",
    "# Distribuci√≥n de montos de transacci√≥n\n",
    "if 'TransactionAmt' in explorer.merged_train.columns:\n",
    "    print(\"\\nüí∞ Distribuci√≥n de montos de transacci√≥n:\")\n",
    "    fraud_amounts = explorer.merged_train[explorer.merged_train['isFraud'] == 1]['TransactionAmt']\n",
    "    legit_amounts = explorer.merged_train[explorer.merged_train['isFraud'] == 0]['TransactionAmt']\n",
    "    \n",
    "    plotting_functions['plot_amount_distribution'](fraud_amounts, legit_amounts)\n",
    "    \n",
    "    # Estad√≠sticas de montos\n",
    "    print(f\"\\nüìä Estad√≠sticas de montos de transacci√≥n:\")\n",
    "    print(f\"\\nFRAUDULENTAS:\")\n",
    "    print(fraud_amounts.describe())\n",
    "    print(f\"\\nLEG√çTIMAS:\")\n",
    "    print(legit_amounts.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd1827",
   "metadata": {},
   "source": [
    "## 11. Visualizaci√≥n de Patrones de Valores Faltantes\n",
    "\n",
    "Matriz de valores faltantes para identificar patrones estructurales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7372c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar patrones de valores faltantes\n",
    "print(\"üï≥Ô∏è Generando visualizaci√≥n de valores faltantes...\")\n",
    "\n",
    "# Matriz de valores faltantes\n",
    "missing_data = missing_results['merged_train']['missing_value_heatmap_data']\n",
    "\n",
    "# Tomar una muestra para visualizaci√≥n (demasiados datos para mostrar todos)\n",
    "sample_size = min(5000, len(missing_data))\n",
    "sample_missing = missing_data.sample(n=sample_size, random_state=42)\n",
    "\n",
    "plotting_functions['plot_missing_value_matrix'](sample_missing)\n",
    "\n",
    "# An√°lisis de patrones de missingness\n",
    "print(\"\\nüîç AN√ÅLISIS DE PATRONES DE VALORES FALTANTES:\")\n",
    "missing_summary = missing_results['merged_train']['missing_summary']\n",
    "\n",
    "# Features completamente vac√≠as\n",
    "completely_missing = missing_summary[missing_summary['missing_percentage'] > 99]\n",
    "print(f\"\\n‚ùå Features casi completamente vac√≠as (>99% missing): {len(completely_missing)}\")\n",
    "if len(completely_missing) > 0:\n",
    "    print(\"  Ejemplos:\", completely_missing['column'].head().tolist())\n",
    "\n",
    "# Features con patrones espec√≠ficos de missing\n",
    "high_missing = missing_summary[(missing_summary['missing_percentage'] > 80) & \n",
    "                              (missing_summary['missing_percentage'] <= 99)]\n",
    "print(f\"\\n‚ö†Ô∏è Features con alta proporci√≥n de valores faltantes (80-99%): {len(high_missing)}\")\n",
    "\n",
    "moderate_missing = missing_summary[(missing_summary['missing_percentage'] > 20) & \n",
    "                                  (missing_summary['missing_percentage'] <= 80)]\n",
    "print(f\"\\nüìä Features con proporci√≥n moderada de valores faltantes (20-80%): {len(moderate_missing)}\")\n",
    "\n",
    "low_missing = missing_summary[(missing_summary['missing_percentage'] > 0) & \n",
    "                             (missing_summary['missing_percentage'] <= 20)]\n",
    "print(f\"\\n‚úÖ Features con baja proporci√≥n de valores faltantes (0-20%): {len(low_missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4cbbe6",
   "metadata": {},
   "source": [
    "## 12. Generaci√≥n de Reporte Comprehensive de EDA\n",
    "\n",
    "Generamos un reporte completo con todos los hallazgos y recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02515847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar visualizaciones y reporte final\n",
    "print(\"üìã Generando reporte comprehensive de EDA...\")\n",
    "\n",
    "# Generar configuraciones de visualizaci√≥n\n",
    "visualizations = explorer.generate_eda_visualizations()\n",
    "\n",
    "# Generar reporte completo\n",
    "eda_report = explorer.generate_eda_report()\n",
    "\n",
    "print(\"\\nüìã REPORTE EJECUTIVO DE EDA:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Metadata del an√°lisis\n",
    "metadata = eda_report['metadata']\n",
    "print(f\"\\nüìÖ Fecha de an√°lisis: {metadata['analysis_date'][:19]}\")\n",
    "print(f\"üìä Dataset: {metadata['dataset_version']}\")\n",
    "print(f\"üîç Versi√≥n de an√°lisis: {metadata['analysis_version']}\")\n",
    "print(f\"üìà Features analizadas: {metadata['total_features_analyzed']}\")\n",
    "\n",
    "# Resumen ejecutivo\n",
    "exec_summary = eda_report['executive_summary']\n",
    "print(f\"\\nüìã RESUMEN EJECUTIVO:\")\n",
    "for key, value in exec_summary.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Recomendaciones clave\n",
    "recommendations = eda_report['recommendations']\n",
    "print(f\"\\nüéØ RECOMENDACIONES CLAVE:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"  {i}. {rec}\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lisis EDA completado exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2e9066",
   "metadata": {},
   "source": [
    "## 13. Hallazgos Clave y Insights para Feature Engineering\n",
    "\n",
    "Documentaci√≥n de los insights m√°s importantes para las siguientes fases del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30068a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumir hallazgos clave para documentaci√≥n\n",
    "print(\"üîç HALLAZGOS CLAVE PARA FEATURE ENGINEERING:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# An√°lisis de la clase objetivo\n",
    "fraud_rate = target_results['basic_distribution']['fraud_rate']\n",
    "class_ratio = target_results['basic_distribution']['class_imbalance_ratio']\n",
    "\n",
    "print(f\"\\nüéØ DESBALANCE DE CLASES:\")\n",
    "print(f\"  ‚Ä¢ Tasa de fraude extremadamente baja: {fraud_rate:.3f}%\")\n",
    "print(f\"  ‚Ä¢ Ratio de desbalance: 1:{class_ratio:.0f}\")\n",
    "print(f\"  ‚Ä¢ IMPLICACI√ìN: Necesidad cr√≠tica de t√©cnicas de balanceamento\")\n",
    "\n",
    "# Features con alta correlaci√≥n\n",
    "if 'target_correlations' in correlation_results:\n",
    "    top_features = list(correlation_results['target_correlations']['strongest_correlations'].keys())[:5]\n",
    "    print(f\"\\nüîó FEATURES M√ÅS PREDICTIVAS:\")\n",
    "    for i, feature in enumerate(top_features, 1):\n",
    "        corr_value = correlation_results['target_correlations']['strongest_correlations'][feature]\n",
    "        print(f\"  {i}. {feature}: {corr_value:.4f}\")\n",
    "\n",
    "# Patrones temporales\n",
    "if 'temporal_patterns' in target_results:\n",
    "    temporal = target_results['temporal_patterns']\n",
    "    print(f\"\\n‚è∞ PATRONES TEMPORALES:\")\n",
    "    print(f\"  ‚Ä¢ Hora pico de fraude: {temporal['peak_fraud_hour']:.0f}:00\")\n",
    "    print(f\"  ‚Ä¢ Variaci√≥n horaria significativa: {temporal['fraud_rate_variance_hourly'] > 0.0001}\")\n",
    "    print(f\"  ‚Ä¢ IMPLICACI√ìN: Features temporales son prometedoras\")\n",
    "\n",
    "# An√°lisis de valores faltantes\n",
    "heavily_missing = missing_results['merged_train']['heavily_missing_features']\n",
    "total_features = missing_results['merged_train']['total_features']\n",
    "\n",
    "print(f\"\\nüï≥Ô∏è VALORES FALTANTES:\")\n",
    "print(f\"  ‚Ä¢ Features con >90% valores faltantes: {heavily_missing}/{total_features}\")\n",
    "print(f\"  ‚Ä¢ Proporci√≥n de features problem√°ticas: {(heavily_missing/total_features)*100:.1f}%\")\n",
    "print(f\"  ‚Ä¢ IMPLICACI√ìN: Estrategia de limpieza y feature selection cr√≠tica\")\n",
    "\n",
    "# Multicolinealidad\n",
    "multicollinear_pairs = len(correlation_results.get('high_correlations', []))\n",
    "print(f\"\\n‚ö†Ô∏è MULTICOLINEALIDAD:\")\n",
    "print(f\"  ‚Ä¢ Pares de features altamente correlacionados: {multicollinear_pairs}\")\n",
    "print(f\"  ‚Ä¢ IMPLICACI√ìN: Reducci√≥n de dimensionalidad necesaria\")\n",
    "\n",
    "# Guardado de datos para siguientes sprints\n",
    "print(f\"\\nüíæ PREPARACI√ìN PARA PR√ìXIMOS SPRINTS:\")\n",
    "print(f\"  ‚Ä¢ Reporte EDA guardado en findings del explorador\")\n",
    "print(f\"  ‚Ä¢ Features clave identificadas para feature engineering\")\n",
    "print(f\"  ‚Ä¢ Estrategias de preprocesamiento definidas\")\n",
    "print(f\"  ‚Ä¢ Baseline para m√©tricas de evaluaci√≥n establecido\")\n",
    "\n",
    "print(\"\\nüéØ EDA RIGUROSO COMPLETADO - LISTO PARA SPRINT 1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2062315e",
   "metadata": {},
   "source": [
    "## 14. Exportaci√≥n de Resultados\n",
    "\n",
    "Guardamos los resultados del an√°lisis para uso en futuros notebooks y scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f3489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar resultados para uso futuro\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Crear directorio de resultados si no existe\n",
    "results_dir = project_root / \"data\" / \"02_processed\"\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Preparar datos para exportaci√≥n (convertir a formato JSON-serializable)\n",
    "export_data = {\n",
    "    'analysis_metadata': {\n",
    "        'date': datetime.now().isoformat(),\n",
    "        'sprint': '1.1 - Rigorous EDA',\n",
    "        'dataset': 'IEEE-CIS Fraud Detection',\n",
    "        'total_samples': len(explorer.merged_train),\n",
    "        'total_features': len(explorer.merged_train.columns)\n",
    "    },\n",
    "    'key_findings': {\n",
    "        'fraud_rate': target_results['basic_distribution']['fraud_rate'],\n",
    "        'class_imbalance_ratio': target_results['basic_distribution']['class_imbalance_ratio'],\n",
    "        'features_with_missing': missing_results['merged_train']['features_with_missing'],\n",
    "        'heavily_missing_features': missing_results['merged_train']['heavily_missing_features'],\n",
    "        'multicollinear_pairs': len(correlation_results.get('high_correlations', []))\n",
    "    },\n",
    "    'top_predictive_features': list(correlation_results['target_correlations']['strongest_correlations'].keys())[:20] if 'target_correlations' in correlation_results else [],\n",
    "    'temporal_insights': {\n",
    "        'peak_fraud_hour': target_results.get('temporal_patterns', {}).get('peak_fraud_hour', None),\n",
    "        'peak_fraud_day': target_results.get('temporal_patterns', {}).get('peak_fraud_day', None)\n",
    "    } if 'temporal_patterns' in target_results else {},\n",
    "    'preprocessing_recommendations': [\n",
    "        'Remove features with >95% missing values',\n",
    "        'Implement sophisticated imputation for important features with moderate missingness',\n",
    "        'Apply class balancing techniques (SMOTE, class weights, or undersampling)',\n",
    "        'Create temporal features (hour, day, week patterns)',\n",
    "        'Engineer interaction features from top predictive features',\n",
    "        'Apply feature selection to handle multicollinearity',\n",
    "        'Normalize/standardize numerical features',\n",
    "        'Encode categorical features with target encoding for high-cardinality variables'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Guardar resultados\n",
    "output_file = results_dir / \"eda_findings_sprint_1_1.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(export_data, f, indent=2, default=str)\n",
    "\n",
    "print(f\"üíæ Resultados exportados a: {output_file}\")\n",
    "print(f\"üìä Tama√±o del archivo: {output_file.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "# Guardar lista de features importantes\n",
    "features_file = results_dir / \"important_features_sprint_1_1.txt\"\n",
    "with open(features_file, 'w') as f:\n",
    "    f.write(\"# Features m√°s importantes identificadas en EDA Sprint 1.1\\n\")\n",
    "    f.write(f\"# Generado: {datetime.now().isoformat()}\\n\\n\")\n",
    "    \n",
    "    if 'target_correlations' in correlation_results:\n",
    "        f.write(\"## Top 20 Features por Correlaci√≥n con isFraud:\\n\")\n",
    "        for i, (feature, corr) in enumerate(correlation_results['target_correlations']['strongest_correlations'].items()):\n",
    "            if i >= 20:\n",
    "                break\n",
    "            f.write(f\"{i+1:2d}. {feature:<30} {corr:8.4f}\\n\")\n",
    "\n",
    "print(f\"üìã Lista de features importantes guardada en: {features_file}\")\n",
    "print(\"\\n‚úÖ SPRINT 1.1 COMPLETADO EXITOSAMENTE!\")\n",
    "print(\"üìà Datos listos para Sprint 1.2 - Feature Engineering\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
